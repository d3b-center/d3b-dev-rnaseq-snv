{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sevenbridges as sbg\n",
    "from sevenbridges.errors import SbgError\n",
    "from sevenbridges.http.error_handlers import rate_limit_sleeper, maintenance_sleeper\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import concurrent.futures\n",
    "from requests import request\n",
    "import json\n",
    "config = sbg.Config(profile='turbo')\n",
    "api = sbg.Api(config=config, error_handlers=[rate_limit_sleeper, maintenance_sleeper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load app into project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to have converted app to json first using rabix!\n",
    "import json\n",
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "f = open('/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/kfdrc_annoFuse_wf.json', 'r')\n",
    "app_raw = f.read()\n",
    "app = json.loads(app_raw)\n",
    "app_id = \"kfdrc-annofuse-wf\"\n",
    "# Create the Workflows\n",
    "a_id = (project + \"/\" + app_id)\n",
    "my_app_first = api.apps.install_app(id = a_id, raw = app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example bash calls from workflow\n",
    "Works best with non-restarted WF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "task_id = \"00210a5f-77ec-4d07-9b1d-c08e5497e24c\"\n",
    "out_file = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08-26_gatk4_rpt.tsv\", \"w\")\n",
    "# task_id = \"3c20cc8e-18d7-43f2-bc2c-4a76d38a88f8\"\n",
    "task = api.tasks.get(task_id)\n",
    "jobs = {}\n",
    "temp = {}\n",
    "for job in task.get_execution_details().jobs:\n",
    "    if job.status == \"COMPLETED\":\n",
    "        check = job.name.split('_')\n",
    "        cmd = job.command_line\n",
    "        if job.command_line == None:\n",
    "            # pdb.set_trace()\n",
    "            cmd = \"embedded script or task retry\"\n",
    "            sys.stderr.write(\"WARN: Job \" + job.name + \" had null cmd\\n\")\n",
    "        if check[-1] == \"s\":\n",
    "            key = \"_\".join(check[:-2])\n",
    "            if key not in temp:\n",
    "                jobs[job.start_time] = {}\n",
    "                jobs[job.start_time][key] = cmd\n",
    "                temp[key] = 1\n",
    "            else:\n",
    "                temp[key] += 1\n",
    "        else:\n",
    "            jobs[job.start_time] = {}\n",
    "            jobs[job.start_time][job.name] = cmd\n",
    "out_file.write(\"Step\\tType\\tNum scatter\\tCommand\\n\")\n",
    "for rtime in sorted(jobs.keys()):\n",
    "    for key in jobs[rtime]:\n",
    "        rtype = \"run step\"\n",
    "        sct = \"NA\"\n",
    "        if key in temp and temp[key] > 1:\n",
    "            rtype = \"scatter\"\n",
    "            sct = str(temp[key])\n",
    "        cmds = jobs[rtime][key].split('\\n')\n",
    "        for cmd in cmds:\n",
    "            out_file.write(key + \"\\t\" + rtype + \"\\t\" + sct + \"\\t\" + cmd + \"\\n\")\n",
    "out_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tsv to markdown table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# max desired col width\n",
    "max_w = 200\n",
    "tsv_in = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08-26_gatk4_rpt.tsv\")\n",
    "out_md = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08-26_gatk4_rpt.md\", \"w\")\n",
    "data = []\n",
    "max_len = []\n",
    "\n",
    "\n",
    "for line in tsv_in:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    data.append(info)\n",
    "    if len(max_len) == 0:\n",
    "        for item in info:\n",
    "            max_len.append(len(item))\n",
    "    else:\n",
    "        for i in range(len(max_len)):\n",
    "            if len(info[i]) > max_w:\n",
    "                max_len[i] = max_w\n",
    "            elif len(info[i]) > max_len[i]:\n",
    "                max_len[i] = len(info[i])\n",
    "# print header first\n",
    "d_ct = []\n",
    "for i in range(len(data[0])):\n",
    "    d_ct.append(len(data[0][i]))\n",
    "    out_md.write(\" | \" + data[0][i] + \"\".join([\" \"] * max_len[i]))\n",
    "    d_ct[i] += max_len[i]\n",
    "out_md.write(\" |\\n\")\n",
    "for i in range(len(data[0])):\n",
    "    out_md.write(\" | \" + \"\".join([\"-\"] * d_ct[i]))\n",
    "out_md.write(\" |\\n\")\n",
    "# pdb.set_trace()\n",
    "for i in range(1, len(data), 1):\n",
    "    for j in range(len(data[i])):\n",
    "        d_ct = len(data[i][j]) + 2\n",
    "        out_md.write(\" | \" + data[i][j] + \"\".join([\" \"] * max_len[j]))\n",
    "        d_ct += max_len[j]\n",
    "    out_md.write(\" |\\n\")\n",
    "out_md.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get run times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get run times by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_run_time(task, phrase):\n",
    "    data = []\n",
    "    if re.search(phrase, task.name):\n",
    "        try:\n",
    "            for job in task.get_execution_details().jobs:\n",
    "                if job.status != \"COMPLETED\":\n",
    "                    sys.stderr.write(\"Skipping job likely killed due to spot instance kill for \" + job.name + \" from task \" + task.id + \"\\n\")\n",
    "                else:\n",
    "                    data.append([job.name, str((job.end_time-job.start_time).seconds/3600)])\n",
    "            # pdb.set_trace()\n",
    "            hold=1\n",
    "            return task.id, task.name, str(task.price.amount), str((task.end_time - task.start_time).seconds/3600), data\n",
    "        except Exception as e:\n",
    "            return [e, task.id]\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "phrase = \"GATK RNAseq SNV RPT\"\n",
    "\n",
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "actual_out = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/cost_est/gatk4_rpt_cov-irt-actual_cost.txt\", \"w\")\n",
    "actual_out.write(\"Task name\\tTask ID\\tCost\\tRun Time in hours\\n\")\n",
    "step_run = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/cost_est/gatk4_rpt_cov-irt_step_run_times.txt\", \"w\")\n",
    "step_run.write(\"Run step\\tRun time in hours\\n\")\n",
    "# for task in tasks:\n",
    "#     result = get_job_run_time(task, phrase)\n",
    "#     if len(result) > 0:\n",
    "#         pdb.set_trace()\n",
    "#         actual_out.write(\"\\t\".join(result[0:4]) + \"\\n\")\n",
    "#         for step in result[4]:\n",
    "#             step_run.write(\"\\t\".join(step) + \"\\n\")\n",
    "x = 1\n",
    "m = 100\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(get_job_run_time, task, phrase): task for task in tasks}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if len(result.result()) > 2:\n",
    "            if x % m == 0:\n",
    "                sys.stderr.write(\"Processed \" + str(x) + \" valid tasks\\n\")\n",
    "            actual_out.write(\"\\t\".join(result.result()[0:4]) + \"\\n\")\n",
    "            for step in result.result()[4]:\n",
    "                step_run.write(\"\\t\".join(step) + \"\\n\")\n",
    "            x += 1\n",
    "        elif len(result.result()) == 2:\n",
    "            sys.stderr.write(str(result.result()[0]) + \"\\tFailed processing task ID \" + result.result()[1] + \"\\n\")\n",
    "            exit(1)\n",
    "actual_out.close()\n",
    "step_run.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_file(info, header):\n",
    "    try:\n",
    "        meta = info.rstrip('\\n').split('\\t')\n",
    "        f_obj = api.files.get(meta[0])\n",
    "        metadata = {}\n",
    "        for i in range(3, len(header), 1):\n",
    "            metadata[header[i]] = meta[i]\n",
    "        f_obj.metadata = metadata\n",
    "        f_obj.save()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\n\")\n",
    "        sys.stderr.write(\"Could not process \" + info)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "manifest = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/rsem_amnifest_to_tag.tsv\")\n",
    "head = next(manifest)\n",
    "header = head.rstrip(\"\\n\").split(\"\\t\")\n",
    "x = 1\n",
    "m = 250\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(tag_file, line, header): line for line in manifest}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' files\\n')\n",
    "            sys.stderr.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GATK4 RNAseq WF Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gatk_refs(api, project):\n",
    "    try:\n",
    "        ref_dict = {}\n",
    "        ref_dict['reference_fasta'] = api.files.get('5f185f0de4b09d9af8ae456e')\n",
    "        ref_dict['reference_dict'] = api.files.get('5f185f09e4b09d9af8ae4569')\n",
    "        known_sites = []\n",
    "        known_sites.append(api.files.get('5f161613e4b0efd84a0fd4b8'))\n",
    "        known_sites.append(api.files.get('5f1615e3e4b0efd84a0fd4a9'))\n",
    "        ref_dict['knownsites'] = known_sites\n",
    "        ref_dict['call_bed_file'] = api.files.get('5f186055e4b09d9af8ae4585')\n",
    "        ref_dict['dbsnp_vcf'] = api.files.get('5f161572e4b0efd84a0fd49f')\n",
    "        ref_dict['tool_name'] = 'STAR_GATK4'\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nFailed to get REFS\\n\")\n",
    "        exit(1)\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_task(in_file):\n",
    "    try:\n",
    "        input_dict = {}\n",
    "        for key in ref_obj:\n",
    "            input_dict[key] = ref_obj[key]\n",
    "        info = in_file.rstrip('\\n').split('\\t')\n",
    "        input_dict['STAR_sorted_genomic_bam'] = api.files.get(info[0])\n",
    "        task_name = \"GATK RNAseq SNV RPT: \" + info[3]\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=input_dict, run=False)\n",
    "        task.inputs['output_basename'] = task.id\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nfailed to set up task for \" + in_file)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'd3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study'\n",
    "app_name = project + \"/d3b-gatk-rnaseq-snv-wf\"\n",
    "manifest = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08-10_bam_list.tsv\")\n",
    "head = next(manifest)\n",
    "ref_obj = get_gatk_refs(api, project)\n",
    "x = 1\n",
    "m = 250\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(draft_task, line ): line for line in manifest}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' tasks\\n')\n",
    "            sys.stderr.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run VEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vep_refs(api, project):\n",
    "    try:\n",
    "        ref_dict = {}\n",
    "        ref_dict['reference'] = api.files.get('5f185f0de4b09d9af8ae456e')\n",
    "        # un comment for using cache\n",
    "        # ref_dict['cache'] = api.files.get('5eed0f54e4b0efd899f4afda')\n",
    "        # ref_dict['merged_cache'] = True\n",
    "        ref_dict['bgzipped_gtf'] = api.files.get('5f3550c2e4b0efd8002a853b')\n",
    "        ref_dict['tool_name'] = 'STAR_GATK4'\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nFailed to get REFS\\n\")\n",
    "        exit(1)\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_vep_task(in_file):\n",
    "    try:\n",
    "        input_dict = {}\n",
    "        for key in ref_obj:\n",
    "            input_dict[key] = ref_obj[key]\n",
    "        info = in_file.rstrip('\\n').split(',')\n",
    "        input_dict['input_vcf'] = api.files.get(info[0])\n",
    "        task_name = \"VEP R100 GTF ANNOTATE RPT: \" + info[sidx]\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=input_dict, run=False)\n",
    "        task.inputs['output_basename'] = task.id\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nfailed to set up task for \" + in_file)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'd3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study'\n",
    "app_name = project + \"/vep-1oo-annotate\"\n",
    "manifest = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08_manifests/vcf-manifest.csv\")\n",
    "head = next(manifest)\n",
    "header = head.rstrip('\\n').split(',')\n",
    "sidx = header.index('sample_id')\n",
    "ref_obj = get_vep_refs(api, project)\n",
    "x = 1\n",
    "m = 250\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(draft_vep_task, line ): line for line in manifest}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' tasks\\n')\n",
    "            sys.stderr.flush()\n",
    "        x += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run STAR Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sf_refs(api, project):\n",
    "    try:\n",
    "        ref_dict = {}\n",
    "        ref_dict['genome_tar'] = api.files.get('5f19e9cee4b0a6d31720b606')\n",
    "        ref_dict['genome_untar_path'] = 'ctat_genome_lib_build_dir'\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nFailed to get REFS\\n\")\n",
    "        exit(1)\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_sf_task(in_file):\n",
    "    try:\n",
    "        input_dict = {}\n",
    "        for key in ref_obj:\n",
    "            input_dict[key] = ref_obj[key]\n",
    "        info = in_file.rstrip('\\n').split(',')\n",
    "        input_dict['Chimeric_junction'] = api.files.get(info[0])\n",
    "        task_name = \"STAR FUSION: \" + info[sidx]\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=input_dict, run=False)\n",
    "        task.inputs['SampleID'] = task.id\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nfailed to set up task for \" + in_file)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'd3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study'\n",
    "app_name = project + \"/star-fusion-covirt\"\n",
    "manifest = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08_manifests/chim_junction-manifest.csv\")\n",
    "head = next(manifest)\n",
    "header = head.rstrip('\\n').split(',')\n",
    "sidx = header.index('sample_id')\n",
    "ref_obj = get_sf_refs(api, project)\n",
    "x = 1\n",
    "m = 250\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(draft_sf_task, line ): line for line in manifest}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' tasks\\n')\n",
    "            sys.stderr.flush()\n",
    "        x += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arriba_refs(api, project):\n",
    "    try:\n",
    "        ref_dict = {}\n",
    "        ref_dict['reference_fasta'] = api.files.get('5f185f0de4b09d9af8ae456e')\n",
    "        ref_dict['gtf_anno'] = api.files.get('5f186055e4b09d9af8ae4585')\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nFailed to get REFS\\n\")\n",
    "        exit(1)\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_arriba_task(samp_id):\n",
    "    try:\n",
    "        input_dict = {}\n",
    "        for key in ref_obj:\n",
    "            input_dict[key] = ref_obj[key]\n",
    "        for key in inputs[samp_id]:\n",
    "            input_dict[key] = api.files.get(inputs[samp_id][key])\n",
    "        task_name = \"ARRIBA FUSION: \" + samp_id\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=input_dict, run=False)\n",
    "        task.inputs['outFileNamePrefix'] = task.id\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nfailed to set up task for \" + in_file)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'd3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study'\n",
    "app_name = project + \"/arriba-fusion\"\n",
    "inputs = {}\n",
    "# process two manifests, chimeric_sam, genome bam + bai, \n",
    "chim_sam = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08_manifests/chimeric_sam-manifest.csv\")\n",
    "head = next(chim_sam)\n",
    "header = head.rstrip('\\n').split(',')\n",
    "sidx = header.index('sample_id')\n",
    "for line in chim_sam:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    inputs[info[sidx]] = {}\n",
    "    inputs[info[sidx]]['chimeric_sam_out'] = info[0]\n",
    "chim_sam.close()\n",
    "ba_manifest = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08_manifests/bam_bai.csv\")\n",
    "head = next(ba_manifest)\n",
    "header = head.rstrip('\\n').split(',')\n",
    "sidx = header.index('sample_id')\n",
    "for line in ba_manifest:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    suffix = info[1][-3:]\n",
    "    inputs[info[sidx]][('genome_aligned_' + suffix)] = info[0]\n",
    "ba_manifest.close()\n",
    "\n",
    "ref_obj = get_arriba_refs(api, project)\n",
    "x = 1\n",
    "m = 250\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(draft_arriba_task, samp_id ): samp_id for samp_id in inputs}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' tasks\\n')\n",
    "            sys.stderr.flush()\n",
    "        x += 1\n",
    "# for samp_id in inputs:\n",
    "#     draft_arriba_task(samp_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run annoFuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_af_refs(api, project):\n",
    "    try:\n",
    "        ref_dict = {}\n",
    "        ref_dict['FusionGenome'] = api.files.get('5f19e9cee4b0a6d31720b606')\n",
    "        ref_dict['genome_untar_path'] = 'ctat_genome_lib_build_dir'\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nFailed to get REFS\\n\")\n",
    "        exit(1)\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_annofuse_task(samp_id):\n",
    "    try:\n",
    "        input_dict = {}\n",
    "        for key in ref_obj:\n",
    "            input_dict[key] = ref_obj[key]\n",
    "        for key in inputs[samp_id]:\n",
    "            input_dict[key] = api.files.get(inputs[samp_id][key])\n",
    "        input_dict['sample_name'] = samp_id\n",
    "        task_name = \"annoFuse: \" + samp_id\n",
    "        task = api.tasks.create(name=task_name, project=project, app=app_name, inputs=input_dict, run=False)\n",
    "        task.inputs['output_basename'] = task.id\n",
    "        task.save()\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(str(e) + \"\\nfailed to set up task for \" + in_file)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'd3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study'\n",
    "app_name = project + \"/kfdrc-annofuse-wf\"\n",
    "inputs = {}\n",
    "# process two manifests, fusion files, rsem, \n",
    "rsem_files = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08-20_rsem_annfuse_manifest.tsv\")\n",
    "head = next(rsem_files)\n",
    "header = head.rstrip('\\n').split('\\t')\n",
    "sidx = header.index('sample_id')\n",
    "for line in rsem_files:\n",
    "    info = line.rstrip('\\n').split('\\t')\n",
    "    inputs[info[sidx]] = {}\n",
    "    inputs[info[sidx]]['rsem_expr_file'] = info[0]\n",
    "rsem_files.close()\n",
    "fusions = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/2020-08-20_fusion_results-manifest.csv\")\n",
    "head = next(fusions)\n",
    "header = head.rstrip('\\n').split(',')\n",
    "sidx = header.index('sample_id')\n",
    "for line in fusions:\n",
    "    info = line.rstrip('\\n').split(',')\n",
    "    key = 'arriba_output_file'\n",
    "    if re.search(\"STAR\", info[1]):\n",
    "        key = 'star_fusion_output_file'\n",
    "    inputs[info[sidx]][key] = info[0]\n",
    "fusions.close()\n",
    "\n",
    "ref_obj = get_af_refs(api, project)\n",
    "x = 1\n",
    "m = 250\n",
    "with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "    results = {executor.submit(draft_annofuse_task, samp_id ): samp_id for samp_id in inputs}\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        if x % m == 0:\n",
    "            sys.stderr.write('Processed ' + str(x) + ' tasks\\n')\n",
    "            sys.stderr.flush()\n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy metadata to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata_to_outputs(task, phrase, in_key):\n",
    "    if re.search(phrase, task.name):\n",
    "        sys.stderr.write('Valid task found ' + task.name + '\\n')\n",
    "        metadata = {}\n",
    "        for key in task.inputs[in_key].metadata:\n",
    "            metadata[key] = task.inputs[in_key].metadata[key]\n",
    "        for out_key in task.outputs:\n",
    "            # pdb.set_trace()\n",
    "            try:\n",
    "                if type(task.outputs[out_key]) is not list:\n",
    "                    file_obj = api.files.get(task.outputs[out_key].id)\n",
    "                    file_obj.metadata = metadata\n",
    "                    file_obj.save()\n",
    "                    try:\n",
    "                        if task.outputs[out_key].secondary_files is not None:\n",
    "                            file_obj = api.files.get(task.outputs[out_key].secondary_files[0].id)\n",
    "                            file_obj.metadata = metadata\n",
    "                            file_obj.save()\n",
    "                    except Exception as e:\n",
    "                        sys.stderr.write(str(e) + \"\\nError processing secondary file for \" + out_key + \" in \" + task.id + \" skipping\\n\")\n",
    "\n",
    "                else:\n",
    "                    for output in task.outputs[out_key]:\n",
    "                        if type(output) is not list:\n",
    "                            file_obj = api.files.get(output.id)\n",
    "                            file_obj.metadata = metadata\n",
    "                            file_obj.save()\n",
    "                        else:\n",
    "                            for item in output:\n",
    "                                if item is not None:\n",
    "                                    file_obj = api.files.get(item.id)\n",
    "                                    file_obj.metadata = metadata\n",
    "                                    file_obj.save()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Skipping \" + out_key + \" for \" + task.name + \" due to error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'VEP R100 GTF ANNOTATE RPT'\n",
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "key = 'input_vcf'\n",
    "print(\"You sure you want to transfer input metadata to outputs with task prefix: \" + prefix + \"? Type \\\"YASS\\\" if so\")\n",
    "check = input()\n",
    "if check == \"YASS\":\n",
    "    tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "    #for task in tasks:\n",
    "    #    add_metadata_to_outputs(task, prefix, key)\n",
    "    x = 1\n",
    "    m = 250\n",
    "    with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "        results = {executor.submit(add_metadata_to_outputs, task, prefix, key ): task for task in tasks}\n",
    "\n",
    "else:\n",
    "    sys.stderr.write(\"User did not type YASS, skipping\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tags to task outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tags_to_outputs(task, phrase, tags):\n",
    "    if re.search(phrase, task.name):\n",
    "        sys.stderr.write('Valid task found ' + task.name + '\\n')\n",
    "        for out_key in task.outputs:\n",
    "            # pdb.set_trace()\n",
    "            try:\n",
    "                if type(task.outputs[out_key]) is not list:\n",
    "                    file_obj = api.files.get(task.outputs[out_key].id)\n",
    "                    file_obj.tags = tags\n",
    "                    file_obj.save()\n",
    "                    try:\n",
    "                        if task.outputs[out_key].secondary_files is not None:\n",
    "                            file_obj = api.files.get(task.outputs[out_key].secondary_files[0].id)\n",
    "                            file_obj.tags = tags\n",
    "                            file_obj.save()\n",
    "                    except Exception as e:\n",
    "                        sys.stderr.write(str(e) + \"\\nError processing secondary file for \" + out_key + \" in \" + task.id + \" skipping\\n\")\n",
    "\n",
    "                else:\n",
    "                    for output in task.outputs[out_key]:\n",
    "                        if type(output) is not list:\n",
    "                            file_obj = api.files.get(output.id)\n",
    "                            file_obj.tags = tags\n",
    "                            file_obj.save()\n",
    "                        else:\n",
    "                            for item in output:\n",
    "                                if item is not None:\n",
    "                                    file_obj = api.files.get(item.id)\n",
    "                                    file_obj.tags = tags\n",
    "                                    file_obj.save()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Skipping \" + out_key + \" for \" + task.name + \" due to error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'VEP R100 GTF ANNOTATE'\n",
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "tags = ['GATK4', 'VEP', 'R100', 'GTF-ANNOTATED']\n",
    "print(\"You sure tag outputs with task prefix: \" + prefix + \"? Type \\\"YASS\\\" if so\")\n",
    "check = input()\n",
    "if check == \"YASS\":\n",
    "    tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "    #for task in tasks:\n",
    "    #    add_metadata_to_outputs(task, prefix, key)\n",
    "    x = 1\n",
    "    m = 250\n",
    "    with concurrent.futures.ThreadPoolExecutor(16) as executor:\n",
    "        results = {executor.submit(add_tags_to_outputs, task, prefix, tags ): task for task in tasks}\n",
    "\n",
    "else:\n",
    "    sys.stderr.write(\"User did not type YASS, skipping\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get task outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_manifest(out_fh, file_obj, out_key, task_name):\n",
    "    out_fh.write(\",\".join([file_obj.id, file_obj.name, out_key, task_name]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "out = open('/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/manifests/test_vep_out.txt', 'w')\n",
    "out.write(\"id,name,output_category,task_name\\n\")\n",
    "phrase = \"VEP R100 ANNOTATE: COVHA-20200311-P1-A01-CP\"\n",
    "\n",
    "for task in tasks:\n",
    "    if re.search(phrase, task.name):\n",
    "        sys.stderr.write('Processing task: ' + task.name + \"\\n\")\n",
    "        for out_key in task.outputs:\n",
    "            if type(task.outputs[out_key]) is not list:\n",
    "                file_obj = task.outputs[out_key]\n",
    "                write_to_manifest(out, file_obj, out_key, task.name)\n",
    "                if task.outputs[out_key].secondary_files is not None:\n",
    "                    write_to_manifest(out, task.outputs[out_key].secondary_files[0], out_key, task.name)\n",
    "            else:\n",
    "                for i in range(len(task.outputs[out_key])):\n",
    "                    if type(task.outputs[out_key][i]) is not list:\n",
    "                        write_to_manifest(out, task.outputs[out_key][i], out_key, task.name)\n",
    "                        if task.outputs[out_key][i].secondary_files is not None:\n",
    "                            write_to_manifest(out, task.outputs[out_key][i].secondary_files[0], out_key, task.name)\n",
    "                    else:\n",
    "                        for j in range(len(task.outputs[out_key][i])):\n",
    "                            if task.outputs[out_key][i][j] is not None:\n",
    "                                write_to_manifest(out, task.outputs[out_key][i][j], out_key, task.name)\n",
    "                                if task.outputs[out_key][i][j].secondary_files is not None:\n",
    "                                    write_to_manifest(out, task.outputs[out_key][i][j].secondary_files[0], out_key, task.name)\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abort unresponsive and restart tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "tasks = api.tasks.query(project=project, status=\"RUNNING\")\n",
    "current = datetime.datetime.now()\n",
    "tz = pytz.timezone('America/New_York')\n",
    "prefix = \"GATK RNAseq SNV\"\n",
    "task_abort = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/TASK_RUN/aborted_and_restarted2.log\", 'w')\n",
    "task_abort.write(\"Task ID\\tTask name\\tNew Task ID\")\n",
    "for task in tasks:\n",
    "    if re.search(prefix, task.name):\n",
    "        for job in task.get_execution_details().jobs:\n",
    "            if job.name == \"preprocess_rnaseq_bam_sambamba_md_sorted\":\n",
    "                if job.status == \"RUNNING\":\n",
    "                    diff = (current-pytz.utc.localize(job.start_time, is_dst=None).astimezone(tz).replace(tzinfo=None)).seconds/3600\n",
    "                    if diff > 2:\n",
    "                        task_abort.write(task.id + \"\\t\" + task.name)\n",
    "                        in_dict = {}\n",
    "                        sys.stderr.write(\"Aborting \" + task.id + \"\\t\" + task.name + \"\\n\" )\n",
    "                        task.abort()\n",
    "                        new_task = task.clone(run=False)\n",
    "                        new_task.inputs['output_basename'] = new_task.id\n",
    "                        new_task.save()\n",
    "                        task_abort.write(\"\\t\" + new_task.id + \"\\n\")\n",
    "                        task_abort.flush()\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "task_abort.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart failed tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "tasks = api.tasks.query(project=project, status=\"FAILED\")\n",
    "prefix = \"GATK RNAseq SNV\"\n",
    "task_restart = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/TASK_RUN/failed_and_restarted2.log\", 'w')\n",
    "task_restart.write(\"Task ID\\tTask name\\tNew Task ID\\n\")\n",
    "run_list = [\"GATK RNAseq SNV: COVHA-20200315-P9-F02-N\",\n",
    "             \"GATK RNAseq SNV: COVHA-20200316-P12-F01-P\",\"GATK RNAseq SNV: COVHA-20200403-P1-C06-P\"]\n",
    "for task in tasks:\n",
    "    if re.search(prefix, task.name) and task.name in run_list:\n",
    "        task_restart.write(task.id + \"\\t\" + task.name)\n",
    "        new_task = task.clone(run=False)\n",
    "        new_task.inputs['output_basename'] = new_task.id\n",
    "        new_task.save()\n",
    "        task_restart.write(\"\\t\" + new_task.id + \"\\n\")\n",
    "        task_restart.flush()\n",
    "task_restart.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Failed list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "tasks = api.tasks.query(project=project, status=\"FAILED\")\n",
    "prefix = \"GATK RNAseq SNV\"\n",
    "task_failed = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/TASK_RUN/failed.log\", 'w')\n",
    "task_failed.write(\"Task ID\\tTask name\\n\")\n",
    "for task in tasks:\n",
    "    if re.search(prefix, task.name):\n",
    "        task_failed.write(task.id + \"\\t\" + task.name + \"\\n\")\n",
    "task_failed.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outputs from failed and aborted tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "tasks = api.tasks.query(project=project, status=\"ABORTED\")\n",
    "prefix = \"GATK RNAseq SNV\"\n",
    "print(\"You sure remove outputs from failed tasks with prefix: \" + prefix + \"? Type \\\"YASS\\\" if so\")\n",
    "check = input()\n",
    "if check == \"YASS\":\n",
    "\n",
    "    for task in tasks:\n",
    "        if re.search(prefix, task.name):\n",
    "            for key in task.outputs:\n",
    "                if task.outputs[key] is not None:\n",
    "                    sys.stderr.write(\"Found files to remove from failed task: \" + task.id + \" \" + task.name + \"\\n\")\n",
    "                    try:\n",
    "                        if task.outputs[key].secondary_files is not None:\n",
    "                            sys.stderr.write(\"Removing secondary files\\n\")\n",
    "                            for i in range(0, len(task.outputs[key].secondary_files), 1):\n",
    "                                task.outputs[key].secondary_files[i].delete()\n",
    "                    except Exception as e:\n",
    "                        sys.stderr.write(str(e) + \"\\nFile with key \" + key + \" probably does not have secondaryFiles, skipping\\n\")\n",
    "                    try:\n",
    "                        task.outputs[key].delete()\n",
    "                    except Exception as e:\n",
    "                        sys.stderr.write(str(e) + \"\\nFile with key \" + key + \" was probably deleted before, skipping\\n\")            \n",
    "                    sys.stderr.write(\"Finished processing \" + task.id + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename _\\d_ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/to_rename.txt\")\n",
    "head = next(manifest)\n",
    "print(\"You sure you want to rename the files in that manifest? Type \\\"YASS\\\" if so\")\n",
    "check = input()\n",
    "sep = \"\\t\"\n",
    "if check == \"YASS\":\n",
    "    for line in manifest:\n",
    "        info = line.split(sep)\n",
    "        cur = api.files.get(info[0])\n",
    "        new_name = cur.name[3:]\n",
    "        sys.stderr.write(\"Renaming file with ID \" + cur.id + \" \" + cur.name + \" to \" + new_name + \"\\n\")\n",
    "        cur.name = new_name\n",
    "        cur.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag outputs by task seq id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "tasks = api.tasks.query(project=project, status=\"COMPLETED\").all()\n",
    "manifest = open('/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/manifests/2020-06-23_UPDATED_HUMAN_MANIFEST.txt')\n",
    "head = next(manifest)\n",
    "header = head.rstrip('\\n').split(\"\\t\")\n",
    "phrase = \"GATK RNAseq SNV RPT\"\n",
    "meta_dict = {}\n",
    "for entry in manifest:\n",
    "    info = entry.rstrip('\\n').split('\\t')\n",
    "    meta_dict[info[0]] = {}\n",
    "    for i in range(0, len(header), 1):\n",
    "        meta_dict[info[0]][header[i]] = info[i]\n",
    "manifest.close()\n",
    "for task in tasks:\n",
    "    if re.search(phrase, task.name):\n",
    "        sys.stderr.write('Processing task: ' + task.name + \"\\n\")\n",
    "        parts = task.name.split()\n",
    "        # Mason lab changed dashes to underscore\n",
    "        seq_id = parts[-1].replace('-','_' )\n",
    "        if seq_id in meta_dict:\n",
    "            for out_key in task.outputs:\n",
    "                if type(task.outputs[out_key]) is not list:\n",
    "                    try:\n",
    "                        file_obj = api.files.get(task.outputs[out_key].id)\n",
    "                        file_obj.metadata = meta_dict[seq_id]\n",
    "                        file_obj.save()\n",
    "                    except Exception as e:\n",
    "                        sys.stderr.write(str(e) + \"\\n\" + file_obj.name + \" probably already tagged, skipping\\n\" )\n",
    "                    try:\n",
    "                        if task.outputs[out_key].secondary_files is not None:\n",
    "                            file_obj = api.files.get(task.outputs[out_key].secondary_files[0].id)\n",
    "                            file_obj.metadata = meta_dict[seq_id]\n",
    "                            file_obj.save()\n",
    "                    except Exception as e:\n",
    "                        sys.stderr.write(str(e) + \"\\nError processing secondary file for \" + out_key + \" in \" + task.id + \" skipping\\n\")\n",
    "\n",
    "        else:\n",
    "            sys.stderr.write(\"Not in manifest: \" + task.name + \" \" + task.id + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete files by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = open(\"/Users/brownm28/Documents/2020-Apr-8_RNAseq_snv_dev/delme_files.txt\")\n",
    "project = \"d3b-bixu/rs-vpf5jbc3-cov-irt-controlled-access-study\"\n",
    "head = next(manifest)\n",
    "print(\"You sure you want to delete the files in that manifest? Type \\\"YASS\\\" if so\")\n",
    "check = input()\n",
    "\n",
    "max_j = 25\n",
    "ct = 0\n",
    "found = 0\n",
    "fnames = []\n",
    "if check == \"YASS\":\n",
    "    for line in manifest:\n",
    "        fnames.append(line.rstrip('\\n'))\n",
    "        ct +=1\n",
    "    sys.stderr.write(\"Searching for \" + str(ct) + \" files to delete\\n\")\n",
    "    total = len(fnames)\n",
    "    for i in range(0, total, max_j):\n",
    "        uset = i + max_j\n",
    "        if uset > total:\n",
    "            uset = total\n",
    "        flist = api.files.query(project=project, names=fnames[i:uset])\n",
    "        for fobj in flist:\n",
    "            sys.stderr.write(\"Deleting \" + fobj.name + \" with ID \" + fobj.id)\n",
    "            fobj.delete()\n",
    "            found += 1\n",
    "    sys.stderr.write(\"Deleted \" + str(found) + \" files\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
